{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import functools\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import re\n",
    "from multiprocessing import Pool, Lock, Value\n",
    "from time import sleep\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url, n_attempts=5, t_sleep=1, **kwargs):\n",
    "    for i in range(n_attempts):\n",
    "        page = requests.get(url, kwargs)\n",
    "        if page.status_code == 200:\n",
    "            return page\n",
    "        sleep(t_sleep)\n",
    "    return None\n",
    "    \n",
    "def log_authors(func):\n",
    "    f_log = open('log_authors.txt', 'a')\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(author_id):\n",
    "        print(func.__name__, author_id, file=f_log)\n",
    "        result = func(author_id)\n",
    "        print('Number of books:', len(result), file=f_log)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_authors\n",
    "def parse_author(author_id):\n",
    "    books = []\n",
    "    page_books = ['start']\n",
    "    page_number = 1\n",
    "    \n",
    "    while page_books:\n",
    "        page = get_page('https://www.respublica.ru/authors/{0}?page={1}'.format(author_id, page_number))\n",
    "        if page is None:\n",
    "            print('Cannot get the page. author_id:', author_id, 'page_mumber:', page_number)\n",
    "            return books\n",
    "            \n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "        listing_products = soup.find('div', {'class': \"rd-page-listing__products\"})\n",
    "        items = listing_products.find_all('div', {'class': \"rd-listing-product-item__title\"})\n",
    "        \n",
    "        page_books = []\n",
    "        for i in items:\n",
    "            page_books.append('https://www.respublica.ru{}'.format(i.find('a').get('href')))\n",
    "\n",
    "        books += page_books\n",
    "        page_number += 1\n",
    "        \n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = [15753, 19769, 15844, 19768, 20948, 43102, 19073, 19071, 20416,\n",
    "            17675, 19076, 20700, 28169, 19805, 20010, 16471, 17717, 19806,\n",
    "            43162, 20935, 16340, 20282, 19075, 15764, 16297, 20591, 26822,\n",
    "            19072, 19725, 20542, 17896, 19070, 20487, 19727, 20540]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2453"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_hrefs = []\n",
    "for id_ in author_ids:\n",
    "    book_hrefs += parse_author(id_)\n",
    "len(book_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('book_hrefs.csv', 'w') as f_csv:\n",
    "    csv_writer = csv.writer(f_csv)\n",
    "    csv_writer.writerows(book_hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_book(href):\n",
    "    card = dict()\n",
    "    #URL\n",
    "    card['URL'] = href\n",
    "    \n",
    "    page = get_page(href)\n",
    "    if page is None:\n",
    "        print('Error occured requesting', href)\n",
    "        return card\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        #Артикул\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__article'})\n",
    "        if item is not None:\n",
    "            item = item.find(itemprop = 'sku')\n",
    "            card['ID'] = item.text\n",
    "\n",
    "        #Название\n",
    "        card['Название'] = soup.find('h1', {'class' : 'rd-page-product__title'}).text\n",
    "\n",
    "        #Автор\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__underline'})\n",
    "        if item is not None:\n",
    "            card['Автор'] = item.text\n",
    "\n",
    "        #Превью\n",
    "        item = soup.find('div', {'class' : 'pages-view'})\n",
    "        if item is not None:\n",
    "            card['Превью'] = 'https://www.respublica.ru{}'.format(\n",
    "                            item.find('a').get('href'))\n",
    "\n",
    "        #Изображение\n",
    "        item = soup.find('img', {'class' : 'rd-page-product__img'})\n",
    "        if item is not None:\n",
    "            card['Изображение'] = 'https://www.respublica.ru{}'.format(\n",
    "                            item.get('src'))\n",
    "\n",
    "        #Описание\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__desc-body'})\n",
    "        if item is not None:\n",
    "            card['Описание'] = item.text\n",
    "\n",
    "        #Цена\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__price'})\n",
    "        if item is not None:\n",
    "            card['Цена'] = float(item.find('span', {'class' : 'num'}).text.replace(' ', ''))\n",
    "\n",
    "        #Цена (старая)\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__price-old'})\n",
    "        if item is not None:\n",
    "            card['Цена (старая)'] = float(item.find('span', {'class' : 'prev'}).text.split()[0])\n",
    "\n",
    "        #В наличии\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__buttons'})\n",
    "        card['В наличии'] = item is not None and item.find('a').text != 'Сообщить о поступлении'\n",
    "\n",
    "        #Категория\n",
    "        item = soup.find('div', {'class' : 'rd-page-breadcrumbs rd-page-product__breadcrumbs'})\n",
    "        if item is not None:\n",
    "            breadcrumps = item.find_all('span', {'class' : 'rd-page-breadcrumbs-item'})\n",
    "            breadcrumps = (br.find(itemprop = 'name').text for br in breadcrumps)\n",
    "            breadcrumps = '; '.join(breadcrumps)\n",
    "        card['Категория'] = breadcrumps\n",
    "\n",
    "        #Число отзывов\n",
    "        #Число оценок\n",
    "        #Оценка\n",
    "        item = soup.find('div', {'class' : 'rd-rating-stars'})\n",
    "        if item is not None:\n",
    "            review_count = soup.find('meta', itemprop = 'reviewCount')\n",
    "            rating_count = soup.find('meta', itemprop = 'ratingCount')\n",
    "            rating_value = soup.find('meta', itemprop = 'ratingValue')\n",
    "\n",
    "            if review_count is not None:\n",
    "                card['Число отзывов'] = int(review_count.get('content'))\n",
    "            else:\n",
    "                card['Число отзывов'] = 0\n",
    "\n",
    "            if rating_count is not None:\n",
    "                card['Число оценок'] = int(rating_count.get('content'))\n",
    "            else:\n",
    "                card['Число оценок'] = 0\n",
    "\n",
    "            if review_count is not None:\n",
    "                card['Оценка'] = float(rating_value.get('content'))\n",
    "\n",
    "        #Карточка\n",
    "        item = soup.find('div', {'class' : 'rd-page-product__desc-params'})\n",
    "        if item is not None:\n",
    "            params = item.find_all('p', {'class' : 'rd-page-product__desc-param'})\n",
    "            for param in params:\n",
    "                name = param.find(itemprop = 'name')\n",
    "                value = param.find(itemprop = 'value')\n",
    "                if name is not None and value is not None:\n",
    "                    card[name.text] = value.text\n",
    "    except:\n",
    "        print('Error occured parsing', href)\n",
    "        \n",
    "    return card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450 objects are processed..."
     ]
    }
   ],
   "source": [
    "mutex = Lock()\n",
    "n_processed = Value('i', 0)\n",
    "\n",
    "def parse_book_wrapper(href):\n",
    "    result = parse_book(href)\n",
    "    with mutex:\n",
    "        global n_processed       \n",
    "        n_processed.value += 1\n",
    "        if n_processed.value % 10 == 0:\n",
    "            print(f\"\\r{n_processed.value} objects are processed...\", end='', flush=True)\n",
    "    return result\n",
    "\n",
    "with Pool(processes=10) as pool:\n",
    "    result = pool.map(parse_book_wrapper, book_hrefs)\n",
    "    \n",
    "with open('hw_3.csv', 'w') as f_csv:\n",
    "    csv_writer = csv.writer(f_csv)\n",
    "    csv_writer.writerows(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
